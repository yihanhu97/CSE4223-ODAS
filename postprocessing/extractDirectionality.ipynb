{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extractDirectionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subroutines\n",
    "Subroutines neccessary for extractDirectionality\n",
    "timeExtract takes the log file to be parsed, and returns the start time and end time in a tuple:<br>\n",
    "    [startTime, endTime]<br>\n",
    "<br>\n",
    "durationinMicroseconds takes the log file to be parsed, and it returns the total duration, startTime, and endTime:<br>\n",
    "    duration, startTime, endTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract time information of each recording from the log file\n",
    "def timeExtract(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Start counting from the last byte\n",
    "        counter = 1\n",
    "        # Go to the 2nd byte before the end of the last line\n",
    "        f.seek(-2, 2) \n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "            counter=counter+1\n",
    "        endTime_line = f.readline().decode()\n",
    "        # Go to the 2nd byte before the end of the last second line\n",
    "        f.seek(-counter-2, 2)\n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "        startTime_line = f.readline().decode()\n",
    "\n",
    "    return [startTime_line, endTime_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate duration of each recording in microseconds\n",
    "def durationinMicroseconds(filename):\n",
    "    startTime = timeExtract(filename)[0].split()[2:]\n",
    "    endTime = timeExtract(filename)[1].split()[2:]\n",
    "    startTimeStr = startTime[0] + ' ' + startTime[1]\n",
    "    endTimeStr = endTime[0] + ' ' + endTime[1]\n",
    "    T1 = datetime.datetime.strptime(startTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    T2 = datetime.datetime.strptime(endTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    delta = T2-T1\n",
    "    duration = delta.seconds*1000000 + delta.microseconds\n",
    "    \n",
    "    return duration, T1, T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: extractDirectionalities\n",
    "Decription:<br>\n",
    "extractDirectionalities accepts a log file generated from data collected from an ODAS microphone, it will then organize the file into a dataframe, where each data point is time, direction, and strength of a single source.<br><br>\n",
    "Parameters:<br>\n",
    "**log file path, Microphopne Number**<br><br>\n",
    "Returns a dataframe with the following columns:<br> \n",
    "**Timestamp, Time, Time In Seconds, Microphone Number, ID, X, Y, Z, Activity** <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extractDirectionalities(filename, mic_number):\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Use repex to store blocks of data into a list\n",
    "    data = re.split('(?<=})\\n(?={)', text)\n",
    "        # Delete the time info from the last data block\n",
    "    tmp = data[-1][:(data[-1].rfind(\"}\")+1)]\n",
    "    data[-1] = tmp\n",
    "\n",
    "    #list of src blocks \n",
    "\n",
    "    srcList = [json.loads(block)[\"src\"] for block in data]\n",
    "    timeList = [json.loads(block)[\"timeStamp\"] for block in data]\n",
    "\n",
    "\n",
    "    #timestamp is the initial time stamp\n",
    "    #time is the datetime value converted from the timestamp and intitial time\n",
    "    #source is a 4 by 6 array where the rows are the source, and the columns are the source values\n",
    "    df = pd.DataFrame(columns = ['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "\n",
    "    #Used for calculating timestamps -> time\n",
    "    duration, startTime, endTime = durationinMicroseconds(filename)\n",
    "    start_time_in_seconds = time.mktime(startTime.timetuple())\n",
    "    t = duration/len(data) / 1000000.0\n",
    "\n",
    "    index = 1.0\n",
    "    ind = 0\n",
    "    df_dict = {}\n",
    "    for block, temp in zip(srcList, timeList):\n",
    "        if block[0][\"id\"] != 0 or block[1][\"id\"] != 0 or block[2][\"id\"] != 0 or block[3][\"id\"] != 0:\n",
    "            time_in_seconds = start_time_in_seconds + (index - 1.0) * t\n",
    "            for i in range(0, 4):\n",
    "                if block[i]['id'] != 0:\n",
    "                    #to do: Fix the interns code: Timestamp != ind\n",
    "                    df_dict[ind] = {\"Timestamp\": temp, \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}\n",
    "                    ind = ind + 1\n",
    "                    #df = df.append(pd.DataFrame({\"Timestamp\": [index], \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}, index=[0]))\n",
    "        index = index + 1.0\n",
    "\n",
    "    df = pd.DataFrame.from_dict(df_dict, orient = 'index')\n",
    "    end = time.time()\n",
    "\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: mergeDirectionalities\n",
    "Decription: <br>\n",
    "mergeDirectionalities will iterate through all the files in \"data\" folder, and it will use extractDirectionalities create each file into a dataframe. The dataframe created will be appended into a master dataframe consiting of all the dataframes created from using extractDirectionalities on each file in \"data\" folder. <br>\n",
    "\n",
    "Prerequirements:<br>\n",
    "All folders in \"data\" folder must be filled with desired .log files in their respective recordingx folders.To do this, run the function above to automate it, or manually download the files from google drive and insert them into the correct folders.<br><br>\n",
    "\n",
    "Parameters:<br>\n",
    "None.<br><br>\n",
    "\n",
    "Returns a dataframe with the following columns:<br> \n",
    "**Timestamp, Time, Time In Seconds, Microphone Number, ID, X, Y, Z, Activity** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mergeDirectionalities():   \n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(columns = ['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "    for i in range(4):\n",
    "        for filename in glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(i) + \"/*.log\"):\n",
    "        #for filename in glob.glob(\"notast4ing\"):\n",
    "            with open(filename, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "            if firstline == \"SST log contains no useful data\\n\":\n",
    "                pass\n",
    "            else:\n",
    "                df1 = extractDirectionalities(filename, i)\n",
    "                df = df.append(df1)\n",
    "            \n",
    "    df = df.sort_values(['Time In Seconds'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: directionalitiesOfMicrophone\n",
    "\n",
    "Description:<br>\n",
    "directionalitiesOfMicrophone takes the directory of all the log files produced by a single microphone, and it will create a dataframe from that data.<br><br>\n",
    "Parameters:<br>\n",
    "String representation of the path from the home directory to the directory of the log files of the given microphone.<br><br>\n",
    "Returns a dataframe with the following columns:<br> \n",
    "**Timestamp, Time, Time In Seconds, Microphone Number, ID, X, Y, Z, Activity** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def diectionalitiesOfMicrophone(microphone_directory):\n",
    "    df = pd.DataFrame(columns = ['Timestamp', 'Time', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "    for filename in glob.glob(microphone_directory +  \"*.log\"):\n",
    "        with open(filename, 'r') as f:\n",
    "            firstline = f.readline()\n",
    "        if firstline == \"SST log contains no useful data\\n\":\n",
    "            pass\n",
    "        else:\n",
    "            df1 = extractDirectionalities(filename, i)\n",
    "            df = df.append(df1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data0 = extractDirectionalities(\"/Users/ardelalegre/CSE4223-ODAS/data/recordings0/cSSt_2019-09-09_14_55_03.log\", 0)\n",
    "\n",
    "X = data[['X', 'Y', 'Z']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(X)\n",
    "plt.scatter(X[:,0], X[:,1], X[:,2])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(data['X'].values,data['Y'].values, data['Z'])\n",
    "ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], kmeans.cluster_centers_[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = mergeDirectionalities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = d[['X', 'Y', 'Z']].values\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=3000, n_init=10, random_state=0)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(x)\n",
    "plt.scatter(x[:,0], x[:,1], x[:,2])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], kmeans.cluster_centers_[:, 2], c='red')\n",
    "ax.scatter(d['X'].values,d['Y'].values, d['Z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020-01-08-09-25-03\n",
    "## K means for January 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_CSV(mic_number):\n",
    "    dataframe = pd.DataFrame(columns = ['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "    for filename in glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(mic_number) + \"/*.log\"):\n",
    "        if(\"2020-01-08\" in filename):\n",
    "            print(filename)\n",
    "            with open(filename, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline == \"SST log contains no useful data\\n\":\n",
    "                    pass\n",
    "            try:\n",
    "                dataframe = extractDirectionalities(filename, mic_number)\n",
    "                dataframe.to_csv(path_or_buf='/home/ardelalegre/CSE4223-ODAS/data/recordings' + str(mic_number) + '/' + filename[48:filename.find('.log')] + '.csv')\n",
    "            except KeyboardInterrupt:\n",
    "                print(nothing)\n",
    "            except:\n",
    "                print(\"Error with \" + filename)\n",
    "    return dataframe   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earliest_day(file0, file1, file2, file3):\n",
    "    compare = []\n",
    "    if(file0.find('cSST') != -1):\n",
    "        compare.append(file0[file0.find('cSST') + 5: file0.find('cSST') + 10 + 5])\n",
    "        \n",
    "    if(file1.find('cSST') != -1):\n",
    "        compare.append(file1[file1.find('cSST') + 5: file1.find('cSST') + 10 + 5])\n",
    "    \n",
    "    if(file2.find('cSST') != -1):\n",
    "        compare.append(file2[file2.find('cSST') + 5: file2.find('cSST') + 10 + 5])\n",
    "    \n",
    "    if(file3.find('cSST') != -1):\n",
    "        compare.append(file3[file3.find('cSST') + 5: file3.find('cSST') + 10 + 5])\n",
    "    \n",
    "    #check year \n",
    "    min_year = 2021\n",
    "    for y in compare:\n",
    "        if(int(y[:4]) < min_year):\n",
    "            min_year = int(y[:4])\n",
    "           \n",
    "    for y in compare:\n",
    "        if(int(y[:4])!= min_year):\n",
    "            del y\n",
    "    \n",
    "    #check month\n",
    "    min_month = 13\n",
    "    for y in compare:\n",
    "        if(int(y[5:7]) < min_month):\n",
    "            min_month = int(y[5:7])\n",
    "           \n",
    "    for y in compare:\n",
    "        if(int(y[5:7])!= min_month):\n",
    "            del y\n",
    "           \n",
    "    #check day\n",
    "    min_day = 32\n",
    "    for y in compare:\n",
    "        if(int(y[5:7]) < min_day):\n",
    "            min_day = int(y[5:7])\n",
    "           \n",
    "    for y in compare:\n",
    "        if(int(y[5:7])!= min_day):\n",
    "            del y\n",
    "            \n",
    "    return compare[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_CSV():\n",
    "    master_list = []\n",
    "    count = 0\n",
    "    total = 0\n",
    "    records0 = []\n",
    "    records1 = []\n",
    "    records2 = []\n",
    "    records3 = []\n",
    "    fridays = [\"2019-09-13\", \"2019-09-20\", \"2019-09-27\", \n",
    "               \"2019-10-4\", \"2019-10-11\", \"2019-10-18\", \"2019-10-25\", \n",
    "               \"2019-11-1\", \"2019-11-8\", \"2019-11-15\", \"2019-11-22\", \"2019-11-29\",\n",
    "               \"2019-12-6\", \"2019-12-13\", \"2019-12-20\", \"2019-12-27\",\n",
    "               \"2020-01-03\", \"2020-01-10\", \"2020-01-17\", \"2020-01-24\", \"2020-01-31\", \n",
    "               \"2020-02-07\", \"2020-02-14\", \"2020-02-21\", \"2020-02-28\",\n",
    "               \"2020-03-06\", \"2020-03-13\", \"2020-03-20\", \"2020-03-27\"]\n",
    "    \n",
    "    temp0 = glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(0) + \"/*.log\")\n",
    "    temp1 = glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(1) + \"/*.log\")\n",
    "    temp2 = glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(2) + \"/*.log\")\n",
    "    temp3 = glob.glob(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings\" + str(3) + \"/*.log\")\n",
    "    \n",
    "    for date in temp0:\n",
    "        for day in fridays:\n",
    "            if day in date:\n",
    "                records0.append(date)\n",
    "                \n",
    "    for date in temp1:\n",
    "        for day in fridays:\n",
    "            if day in date:\n",
    "                records1.append(date)\n",
    "            \n",
    "    for date in temp2:\n",
    "        for day in fridays:\n",
    "            if day in date:\n",
    "                records2.append(date)\n",
    "            \n",
    "    for date in temp3:\n",
    "        for day in fridays:\n",
    "            if day in date:\n",
    "                records3.append(date)\n",
    "   \n",
    "    records0.sort()\n",
    "    records1.sort()\n",
    "    records2.sort()\n",
    "    records3.sort()\n",
    "\n",
    "    curDay = \"\"\n",
    "    temp = \"\"\n",
    "    for mic0,mic1,mic2,mic3 in zip(records0,records1,records2,records3):\n",
    "        curDay = mic0[mic0.find(\"cSST\"): mic0.find(\"cSST\") + 15]\n",
    "        if temp != curDay:\n",
    "            dict_to_csv(master_list, curDay)\n",
    "            temp = curDay\n",
    "            master_list = []\n",
    "            \n",
    "        if curDay in mic0:\n",
    "            with open(mic0, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline == \"SST log contains no useful data\\n\":\n",
    "                    pass\n",
    "                else:\n",
    "                    df0 = extractDirectionalities(mic0,0)\n",
    "                    count = count + 1\n",
    "                    for index, row in df0.iterrows():\n",
    "                        dic = {}\n",
    "                        dic['Timestamp'] = row['Timestamp']\n",
    "                        dic['Time'] = row['Time']\n",
    "                        dic['Time In Seconds'] = row['Time In Seconds']\n",
    "                        dic['Microphone Number'] = row['Microphone Number']\n",
    "                        dic['Source ID'] = row['Source ID']\n",
    "                        dic['X'] = row['X']\n",
    "                        dic['Y'] = row['Y']\n",
    "                        dic['Z'] = row['Z']\n",
    "                        dic['Activity'] = row['Activity']\n",
    "                        master_list.append(dic)\n",
    "\n",
    "\n",
    "                    \n",
    "        if curDay in mic1:\n",
    "            with open(mic1, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline ==  \"SST log contains no useful data\\n\":\n",
    "                    pass\n",
    "                else:\n",
    "                    df1 = extractDirectionalities(mic1,1)\n",
    "                    for index, row in df1.iterrows():\n",
    "                        dic = {}\n",
    "                        dic['Timestamp'] = row['Timestamp']\n",
    "                        dic['Time'] = row['Time']\n",
    "                        dic['Time In Seconds'] = row['Time In Seconds']\n",
    "                        dic['Microphone Number'] = row['Microphone Number']\n",
    "                        dic['Source ID'] = row['Source ID']\n",
    "                        dic['X'] = row['X']\n",
    "                        dic['Y'] = row['Y']\n",
    "                        dic['Z'] = row['Z']\n",
    "                        dic['Activity'] = row['Activity']\n",
    "                        master_list.append(dic)\n",
    "\n",
    "\n",
    "                    \n",
    "        if curDay in mic2:\n",
    "            with open(mic2, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline ==  \"SST log contains no useful data\\n\":\n",
    "                    pass\n",
    "                else:\n",
    "                    df2 = extractDirectionalities(mic2,2)\n",
    "                    for index, row in df2.iterrows():\n",
    "                        dic = {}\n",
    "                        dic['Timestamp'] = row['Timestamp']\n",
    "                        dic['Time'] = row['Time']\n",
    "                        dic['Time In Seconds'] = row['Time In Seconds']\n",
    "                        dic['Microphone Number'] = row['Microphone Number']\n",
    "                        dic['Source ID'] = row['Source ID']\n",
    "                        dic['X'] = row['X']\n",
    "                        dic['Y'] = row['Y']\n",
    "                        dic['Z'] = row['Z']\n",
    "                        dic['Activity'] = row['Activity']\n",
    "                        master_list.append(dic)\n",
    "                    \n",
    "        if curDay in mic3:\n",
    "            with open(mic3, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline ==  \"SST log contains no useful data\\n\":\n",
    "                    pass\n",
    "                else:\n",
    "                    df3 = extractDirectionalities(mic3,3)\n",
    "                    for index, row in df3.iterrows():\n",
    "                        dic = {}\n",
    "                        dic['Timestamp'] = row['Timestamp']\n",
    "                        dic['Time'] = row['Time']\n",
    "                        dic['Time In Seconds'] = row['Time In Seconds']\n",
    "                        dic['Microphone Number'] = row['Microphone Number']\n",
    "                        dic['Source ID'] = row['Source ID']\n",
    "                        dic['X'] = row['X']\n",
    "                        dic['Y'] = row['Y']\n",
    "                        dic['Z'] = row['Z']\n",
    "                        dic['Activity'] = row['Activity']\n",
    "                        master_list.append(dic)\n",
    "\n",
    "    dict_to_csv(master_list,curDay)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_csv(master_list, curDay):\n",
    "    if len(master_list) == 0:\n",
    "        return\n",
    "    print(\"starting for \" + curDay )\n",
    "    master_list = sorted(master_list, key = lambda i: i['Time In Seconds'])            \n",
    "    masterDataFrame = pd.DataFrame(master_list)\n",
    "    beginTime = masterDataFrame['Time In Seconds'].iloc[0]\n",
    "    split = beginTime + 3600\n",
    "    hour = 0\n",
    "    counter = 0\n",
    "    master_sorted_list = []\n",
    "    for index, row in masterDataFrame.iterrows():\n",
    "        beginTime = row['Time In Seconds']\n",
    "        if beginTime < split:\n",
    "            dic = {}\n",
    "            dic['Timestamp'] = row['Timestamp']\n",
    "            dic['Time'] = row['Time']\n",
    "            dic['Time In Seconds'] = row['Time In Seconds']\n",
    "            dic['Microphone Number'] = row['Microphone Number']\n",
    "            dic['Source ID'] = row['Source ID']\n",
    "            dic['X'] = row['X']\n",
    "            dic['Y'] = row['Y']\n",
    "            dic['Z'] = row['Z']\n",
    "            master_sorted_list.append(dic)\n",
    "        else:\n",
    "            hourlyCSV = pd.DataFrame(master_sorted_list)\n",
    "            hourlyCSV['tempMic'] = hourlyCSV['Microphone Number'].shift(-1)\n",
    "            hourlyCSV['tempTime'] = hourlyCSV['Time In Seconds'].shift(-1)\n",
    "            hourlyCSV['Multi Source'] = (hourlyCSV['Microphone Number'] != hourlyCSV['tempMic']) \n",
    "            hourlyCSV = hourlyCSV.drop(columns = ['tempMic','tempTime'])\n",
    "            hourlyCSV.to_csv(path_or_buf='/Users/brian_wangst/Desktop/mlr/data/Fridays/' + str(hourlyCSV['Time'][0]) + \"hour\" + str(hour) + '.csv')\n",
    "            hour = hour + 1\n",
    "            master_sorted_list = []\n",
    "            split = beginTime + 3600\n",
    "            \n",
    "    hourlyCSV = pd.DataFrame(master_sorted_list)        \n",
    "    hourlyCSV['tempMic'] = hourlyCSV['Microphone Number'].shift(-1)\n",
    "    hourlyCSV['tempTime'] = hourlyCSV['Time In Seconds'].shift(-1)\n",
    "    hourlyCSV['Multi Source'] = (hourlyCSV['Microphone Number'] != hourlyCSV['tempMic'])\n",
    "    hourlyCSV = hourlyCSV.drop(columns = ['tempMic','tempTime'])\n",
    "    hourlyCSV.to_csv(path_or_buf='/Users/brian_wangst/Desktop/mlr/data/Fridays' + str(hourlyCSV['Time'][0]) + \"hour\" + str(hour) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting for cSST_2019-09-27\n",
      "starting for cSST_2019-10-18\n",
      "starting for cSST_2019-11-15\n",
      "starting for cSST_2019-11-22\n",
      "starting for cSST_2019-11-22\n"
     ]
    }
   ],
   "source": [
    "combine_CSV()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one = to_CSV(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "two = to_CSV(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "three = to_CSV(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def csv_to_dataframe(mic_number):\n",
    "    df = pd.DataFrame(columns = ['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "    for filename in glob.glob(\"/home/ardelalegre/CSE4223-ODAS/data/recordings\" + str(mic_number) + '/*.csv'):\n",
    "        df = df.append(pd.read_csv(filename))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df0 = csv_to_dataframe(0)\n",
    "df1 = csv_to_dataframe(1)\n",
    "df2 = csv_to_dataframe(2)\n",
    "df3 = csv_to_dataframe(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df0, df1, df2, df3])\n",
    "df = df.sort_values(['Time In Seconds'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(df['Microphone Number'])\n",
    "#arr = arr[4000000:]\n",
    "dff = arr[1:] - arr[:-1]\n",
    "dff = dff != 0\n",
    "dff = np.append(dff, 0)\n",
    "df['diff']  = dff\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"combinedFor1-8-20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh combinedFor1-8-20.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(dff)[0]\n",
    "index[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones(1000)\n",
    "smooth = np.convolve(dff, kernel)\n",
    "plt.plot(smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df3[['X', 'Y', 'Z']].values\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=3000, n_init=10, random_state=0)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=6, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(x)\n",
    "plt.scatter(x[:,0], x[:,1], x[:,2])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "#ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], kmeans.cluster_centers_[:, 2], c='red')\n",
    "ax.scatter(df['X'].values,df['Y'].values, df['Z'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df0[['X', 'Y', 'Z']].values\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=3000, n_init=10, random_state=0)\n",
    "    kmeans.fit(x)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "pred_y = kmeans.fit_predict(x)\n",
    "plt.scatter(x[:,0], x[:,1], x[:,2])\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "#ax.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], kmeans.cluster_centers_[:, 2], c='red')\n",
    "ax.scatter(df['X'].values,df['Y'].values, df['Z'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extractDirectionalities(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings0/cSST_2020-01-08_09:00:03.log\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extractDirectionalities(\"/Users/brian_wangst/Google Drive File Stream/My Drive/ODAS/recordings0/cSST_2020-01-08_09:00:03.log\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
