{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Steps:\n",
    "- [ ]  Sound source matching\n",
    "- [ ]  Timestamp matching\n",
    "- [ ]  Delay and significance calculation\n",
    "- [ ]  Extract coordinates\n",
    "- [ ]  Populate dataframe\n",
    "\n",
    "======================================================================================================================\n",
    "### Current Goal:\n",
    "Formulate data frame for 1 min recording from 1:05 pm - 1:15pm, on March 25th. Single stationary source.\n",
    "\n",
    "======================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sound Source Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MS+LP: \n",
    "For 1 min recording starting at 1:05pm, given a window length of 1s and 4 arrays (16 channels). \n",
    "The number of cross correlation calculation is 60s/1s * (16 pick 2).\n",
    "'''\n",
    "import soundfile as sf\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def truncate(sig1, sig2):\n",
    "    '''\n",
    "    This function truncates the longer signal and return two signals of the same length\n",
    "    '''\n",
    "    l1, l2 = len(sig1), len(sig2)\n",
    "    if l1 <= l2:\n",
    "        return sig1, sig2[0:l1]\n",
    "    else:\n",
    "        return sig1[0:l2], sig2\n",
    "    \n",
    "def padding(sig1, sig2):\n",
    "    '''\n",
    "    This function pads the shorter sequence to the length of longer sequence with 0\n",
    "    '''\n",
    "    length = np.maximum(len(sig1), len(sig2))\n",
    "    l1, l2 = len(sig1), len(sig2)\n",
    "    if l1 < length:\n",
    "        return np.concatenate((sig1, np.linspace(0,0,length - l1))), sig2\n",
    "    if l2 < length:\n",
    "        return sig1, np.concatenate((sig2, np.linspace(0,0,length - l2)))\n",
    "\n",
    "def prepadding(sig1, sig2, winDuration, Fs):\n",
    "    l = winDuration * Fs\n",
    "    N = len(sig1)    \n",
    "    # Padding to have an interger number of windows\n",
    "    if N%l != 0:\n",
    "        padWidth = l-N%l\n",
    "        sig1 = np.pad(sig1, (0, padWidth), 'constant', constant_values = 0)\n",
    "        sig2 = np.pad(sig2, (0, padWidth), 'constant', constant_values = 0)\n",
    "        \n",
    "    numOfWindows = len(sig1)/l\n",
    "    \n",
    "    return sig1, sig2, numOfWindows\n",
    "\n",
    "def whiten(sig):\n",
    "    return sig/np.abs(sig)\n",
    "\n",
    "def gcc_phat(sig1, sig2, fs=16000, max_tau=None, interp=1, window=True, windowName=\"hamming\"):\n",
    "    '''\n",
    "    This function computes the offset between the signal sig and the reference signal refsig\n",
    "    using the Generalized Cross Correlation - Phase Transform (GCC-PHAT) method. In this modified\n",
    "    function, sig1 and sig2 are garuanteed to have the same length\n",
    "    '''\n",
    "    # Make sure the length for the FFT is larger or equal than len(sig) + len(refsig)\n",
    "    # n1, n2 = sig1.shape[0], sig2.shape[0]\n",
    "    n = sig1.shape[0]\n",
    "    \n",
    "    # Add window\n",
    "    if window: \n",
    "        win1 = getattr(np, windowName)(n)\n",
    "        win2 = getattr(np, windowName)(n)\n",
    "        sig1 = sig1 * win1\n",
    "        sig2 = sig2 * win2\n",
    "\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    SIG1 = np.fft.rfft(sig1, n=n)\n",
    "    SIG2 = np.fft.rfft(sig2, n=n) \n",
    "    W1 = whiten(SIG1)\n",
    "    W2 = whiten(SIG2)\n",
    "    \n",
    "    R = W1 * np.conj(W2)\n",
    "    \n",
    "    cc = np.fft.irfft(R, n=(interp * n))\n",
    "\n",
    "    # cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n",
    "\n",
    "    max_shift = int(interp * n / 2)\n",
    "    if max_tau:\n",
    "        max_shift = np.minimum(int(interp * fs * max_tau), max_shift)\n",
    "\n",
    "    cc = np.concatenate((cc[-max_shift:], cc[:max_shift+1]))\n",
    "\n",
    "    # find max cross correlation index\n",
    "    shift = np.argmax(np.abs(cc)) - max_shift\n",
    "\n",
    "    tau = np.float(shift / float(interp * fs))\n",
    "    \n",
    "    if(np.any(np.isnan(cc))): \n",
    "        tau = math.nan\n",
    "    \n",
    "    return tau, cc, R, SIG1, SIG2\n",
    "\n",
    "\n",
    "def width_cc(cc, threshold=0.5):\n",
    "    '''\n",
    "    Calculate the width between the first sample and the last sample that are above the thresold.\n",
    "    Threshold is precentage of the peak value\n",
    "    '''\n",
    "    cc_max = np.amax(cc)\n",
    "    peak_index = np.where(cc == cc_max)\n",
    "    mag_thr = threshold * cc_max\n",
    "    width = 0\n",
    "    for ii in range(len(cc)):\n",
    "        if cc[ii] > mag_thr:\n",
    "            width = width + 1\n",
    "    return width\n",
    "\n",
    "def significance(cc):\n",
    "    '''\n",
    "    Calculate the significance of each cross correlation sequence\n",
    "    '''\n",
    "    cc_mean = np.mean(cc)\n",
    "    cc_std = np.std(cc)\n",
    "    return (np.amax(cc) - cc_mean)/cc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data:\n",
    "    Operate with a chronigical order. Data might be missing from one or more than one array.\n",
    "    Computation is reduced when not all arrays have data.\n",
    "'''\n",
    "data0,samplerate = sf.read('/Users/hyh/Desktop/Test Files/New/postfiltered_2020-03-25_13_05_11_0.raw',\n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )\n",
    "data1,samplerate = sf.read('/Users/hyh/Desktop/Test Files/New/postfiltered_2020-03-25_13_05_13_1.raw', \n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )\n",
    "data2,samplerate = sf.read('/Users/hyh/Desktop/Test Files/New/postfiltered_2020-03-25_13_05_11_2.raw', \n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )\n",
    "data3,samplerate = sf.read('/Users/hyh/Desktop/Test Files/New/postfiltered_2020-03-25_13_05_11_3.raw', \n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "16 pick 2:\n",
    "    arrays: contains the index of arrays that are read, it will at least have 2 indices\n",
    "'''\n",
    "arrays = [0,1,2,3]\n",
    "channels = [0,1,2,3]\n",
    "arrayCombs = list(it.combinations_with_replacement(arrays, 2))\n",
    "channelCombs = list(it.product(channels, repeat=2))\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for aComb in arrayCombs:\n",
    "    arr1, arr2 = aComb\n",
    "    count1 = count1 + 1\n",
    "    for cComb in channelCombs:\n",
    "        chan1, chan2 = cComb\n",
    "        count2 = count2 + 1\n",
    "        print(chan1, chan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestamp Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_matching(path):\n",
    "    df = pd.read_csv(path)\n",
    "    master_list = []\n",
    "    start_time = df['Time In Seconds'].iloc[0]\n",
    "    split = start_time + 0.008\n",
    "    end_time = df['Time In Seconds'].iloc[-1]\n",
    "    array_0 = 0\n",
    "    array_1 = 0\n",
    "    array_2 = 0\n",
    "    array_3 = 0\n",
    "    counter = 0\n",
    "    count = 0\n",
    "    #Assuming only 1 channel for each array\n",
    "    for row in df.iterrows():\n",
    "        count = count + 1\n",
    "        if row[1]['Time In Seconds'] >= split:\n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_0[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_1[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_0['X'],array_0['Y'],array_0['Z'] ]\n",
    "            dic['xyz 2'] = [array_1['X'],array_1['Y'],array_1['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_0[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_2[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_0['X'],array_0['Y'],array_0['Z'] ]\n",
    "            dic['xyz 2'] = [array_2['X'],array_2['Y'],array_2['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_0[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_3[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_0['X'],array_0['Y'],array_0['Z'] ]\n",
    "            dic['xyz 2'] = [array_3['X'],array_3['Y'],array_3['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_1[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_2[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_1['X'],array_1['Y'],array_1['Z'] ]\n",
    "            dic['xyz 2'] = [array_2['X'],array_2['Y'],array_2['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_1[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_3[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_1['X'],array_1['Y'],array_1['Z'] ]\n",
    "            dic['xyz 2'] = [array_3['X'],array_3['Y'],array_3['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            dic = {}\n",
    "            dic['Column 1'] = array_2[\"Microphone Number\"] \n",
    "            dic['Column 2'] = array_3[\"Microphone Number\"]\n",
    "            dic['xyz 1'] = [array_2['X'],array_2['Y'],array_2['Z'] ]\n",
    "            dic['xyz 2'] = [array_3['X'],array_3['Y'],array_3['Z'] ]\n",
    "            dic['Grouping Time'] = split - 0.008\n",
    "            master_list.append(dic)\n",
    "            \n",
    "            split = split + 0.008\n",
    "\n",
    "            array_0 = 0\n",
    "            array_1 = 0\n",
    "            array_2 = 0\n",
    "            array_3 = 0\n",
    "            \n",
    "\n",
    "            if len(master_list) >= 50000:\n",
    "                output = pd.DataFrame(master_list)\n",
    "                output.to_csv(path_or_buf= \"/Users/hyh/Desktop/\" + path[path.find(\"data/\") + 5: path.find(\"hour\") - 1] + \"_\" + str(counter) + \".csv\")\n",
    "                master_list = []\n",
    "                counter = counter + 1\n",
    "                \n",
    "        if row[1]['Microphone Number'] == 0:\n",
    "            array_0 = row[1]\n",
    "        elif row[1]['Microphone Number'] == 1:\n",
    "            array_1 = row[1]\n",
    "        elif row[1]['Microphone Number'] == 2:\n",
    "            array_2 = row[1]\n",
    "        else:\n",
    "            array_3 = row[1]\n",
    "                \n",
    "    output = pd.DataFrame(master_list)\n",
    "    output.to_csv(path_or_buf= \"/Users/hyh/Desktop/\" + path[path.find(\"data/\") + 5:path.find(\"hour\") - 1] + \"_\" + str(counter) + \".csv\")\n",
    "                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_matching(\"/Users/hyh/Desktop/recordingWednesday, March 25, 2020 01:05:31hour1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
