{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import scipy as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data1,samplerate = sf.read('C:/Users/lenovo/Desktop/ODAS_4223_0108/postfiltered_2020-01-08_09_25_03_1.raw', \n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )\n",
    "data2,samplerate = sf.read('C:/Users/lenovo/Desktop/ODAS_4223_0108/postfiltered_2020-01-08_09_25_03_2.raw', \n",
    "               channels=4, \n",
    "               samplerate=16000,\n",
    "               subtype='PCM_16'\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def truncate(sig1, sig2):\n",
    "    '''\n",
    "    This function truncates the longer signal and return two signals of the same length\n",
    "    '''\n",
    "    l1, l2 = len(sig1), len(sig2)\n",
    "    if l1 <= l2:\n",
    "        return sig1, sig2[0:l1]\n",
    "    else:\n",
    "        return sig1[0:l2], sig2\n",
    "\n",
    "def prepadding(sig1, sig2, winDuration, Fs):\n",
    "    l = winDuration * Fs\n",
    "    N = len(sig1)    \n",
    "    # Padding to have an interger number of windows\n",
    "    if N%l != 0:\n",
    "        padWidth = l-N%l\n",
    "        sig1 = np.pad(sig1, (0, padWidth), 'constant', constant_values = 0)\n",
    "        sig2 = np.pad(sig2, (0, padWidth), 'constant', constant_values = 0)\n",
    "        \n",
    "    numOfWindows = len(sig1)/l\n",
    "    \n",
    "    return sig1, sig2, numOfWindows\n",
    "\n",
    "def whiten(sig):\n",
    "    return sig/np.abs(sig)\n",
    "\n",
    "def gcc_phat(sig1, sig2, fs=16000, max_tau=None, interp=1, window=True, windowName=\"hamming\"):\n",
    "    '''\n",
    "    This function computes the offset between the signal sig and the reference signal refsig\n",
    "    using the Generalized Cross Correlation - Phase Transform (GCC-PHAT)method. In this modified\n",
    "    function, sig1 and sig2 are garuanteed to have the same length\n",
    "    '''\n",
    "    # Make sure the length for the FFT is larger or equal than len(sig) + len(refsig)\n",
    "    # n1, n2 = sig1.shape[0], sig2.shape[0]\n",
    "    n = sig1.shape[0]\n",
    "    \n",
    "    # Add window\n",
    "    if window: \n",
    "        win1 = getattr(np, windowName)(n)\n",
    "        win2 = getattr(np, windowName)(n)\n",
    "        sig1 = sig1 * win1\n",
    "        sig2 = sig2 * win2\n",
    "\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    SIG1 = np.fft.rfft(sig1, n=n)\n",
    "    SIG2 = np.fft.rfft(sig2, n=n)\n",
    "    \n",
    "    W1 = whiten(SIG1)\n",
    "    W2 = whiten(SIG2)\n",
    "    \n",
    "    R = W1 * np.conj(W2)\n",
    "    \n",
    "    cc = np.fft.irfft(R, n=(interp * n))\n",
    "\n",
    "    # cc = np.fft.irfft(R / np.abs(R), n=(interp * n))\n",
    "\n",
    "    max_shift = int(interp * n / 2)\n",
    "    if max_tau:\n",
    "        max_shift = np.minimum(int(interp * fs * max_tau), max_shift)\n",
    "\n",
    "    cc = np.concatenate((cc[-max_shift:], cc[:max_shift+1]))\n",
    "\n",
    "    # find max cross correlation index\n",
    "    shift = np.argmax(np.abs(cc)) - max_shift\n",
    "\n",
    "    tau = np.float(shift / float(interp * fs))\n",
    "    \n",
    "    if(np.any(np.isnan(cc))): \n",
    "        tau = math.nan\n",
    "    \n",
    "    return tau, cc, R, SIG1, SIG2\n",
    "\n",
    "\n",
    "def width_cc(cc, threshold=0.5):\n",
    "    '''\n",
    "    Calculate the width between the first sample and the last sample that are above the thresold.\n",
    "    Threshold is precentage of the peak value\n",
    "    '''\n",
    "    cc_max = np.amax(cc)\n",
    "    peak_index = np.where(cc == cc_max)\n",
    "    mag_thr = threshold * cc_max\n",
    "    width = 0\n",
    "    for ii in range(len(cc)):\n",
    "        if cc[ii] > mag_thr:\n",
    "            width = width + 1\n",
    "    return width\n",
    "\n",
    "def significance(cc):\n",
    "    '''\n",
    "    Calculate the significance of each cross correlation sequence\n",
    "    '''\n",
    "    cc_mean = np.mean(cc)\n",
    "    cc_std = np.std(cc)\n",
    "    return (np.amax(cc) - cc_mean)/cc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 286\n",
    "time = np.linspace(1,286,286)\n",
    "time.T.shape\n",
    "time = [time,time]\n",
    "np.shape(np.array(time).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If time range is given, say between 2020-01-08, 09:10 - 09:30\n",
    "timeRange = ['2020-01-08_09_10',\n",
    "             '2020-01-08_09_15',\n",
    "             '2020-01-08_09_20',\n",
    "             '2020-01-08_09_25',\n",
    "             '2020-01-08_09_30'\n",
    "            ]\n",
    "\n",
    "# Extract any files that exsist within this time range. For testing, I am only using array 2 and array 3\n",
    "for time in timeRange:\n",
    "    path_in_str_list = []\n",
    "    pathlist = Path('/Users/hyh/Desktop/Test Files/Postfiltered/').glob('*'+time+'*[2-3].raw')\n",
    "    for path in pathlist:\n",
    "        # because path is object not string\n",
    "        path_in_str = str(path)\n",
    "        path_in_str_list.append(path_in_str)\n",
    "        path_in_str_list.sort()\n",
    "    # Load data\n",
    "    data1,samplerate = sf.read(path_in_str_list[0], \n",
    "                   channels=4, \n",
    "                   samplerate=16000,\n",
    "                   subtype='PCM_16'\n",
    "                  )\n",
    "    data2,samplerate = sf.read(path_in_str_list[1], \n",
    "                   channels=4, \n",
    "                   samplerate=16000,\n",
    "                   subtype='PCM_16'\n",
    "                  )\n",
    "    # Then do cross correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# Return the table \n",
    "Fs = 16000\n",
    "total_time = int(np.minimum(len(data1), len(data2))/Fs)\n",
    "window_len = 1 # how many seconds in a window\n",
    "l = Fs * window_len\n",
    "num_channel = 4\n",
    "# Initialize empty arrays\n",
    "time_vector = np.linspace(1,total_time, total_time)\n",
    "delay_vector = np.zeros(total_time)\n",
    "width_vector = np.zeros(total_time)\n",
    "significance_vector = np.zeros(total_time)\n",
    "table_pair = np.zeros([total_time, 4])\n",
    "table = np.zeros([num_channel, num_channel, total_time, 4])\n",
    "\n",
    "for channel1 in range(num_channel):\n",
    "    for channel2 in range(num_channel):\n",
    "        for ii in range(total_time):\n",
    "            sig1, sig2 = truncate(data2[:,channel1], data2[:,channel2])\n",
    "            sig1Temp, sig2Temp = sig1[ii * l:(ii + 1)* l], sig2[ii * l:(ii + 1)* l]\n",
    "            tau, cc, R, SIG1, SIG2 = gcc_phat(sig1Temp, sig2Temp, fs=16000)\n",
    "            width1 = width_cc(cc,0.5)\n",
    "            significance1 = significance(cc)\n",
    "            delay_vector[ii] = tau\n",
    "            width_vector[ii] = width1\n",
    "            significance_vector[ii] = significance1\n",
    "        table_pair = np.array([time_vector, delay_vector, width_vector, significance_vector]).T\n",
    "        table[channel1, channel2, :, :] = table_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('table.npy',table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('table.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 286, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into 16 dataframes, represents 16 combinations between two microphones.\n",
    "filename = \"postfiltered_2020-01-08_09_25_03\"\n",
    "arrayA   = \"1\"\n",
    "arrayB   = \"2\"\n",
    "channels = [0,1,2,3]\n",
    "columnNames = [\"Delay\",\"Width\",\"Sig\"]\n",
    "combs = itertools.product(channels, repeat=2)\n",
    "\n",
    "for aComb in combs:\n",
    "    cha1, cha2= aComb\n",
    "    tmp = data[cha1,cha2,:,:]\n",
    "    # Generate a column that tells the combination\n",
    "    combCol = [str(cha1)+str(cha2)] * tmp.shape[0]\n",
    "    d = pd.DataFrame(tmp[:,1:], index=tmp[:,0], columns=columnNames)\n",
    "    d.insert(0, \"Comb\", combCol, True) \n",
    "    d.to_csv(\"ccResults/\"+filename+\"_\"+arrayA+arrayB+\"_\"+str(cha1)+str(cha2)+\".csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
