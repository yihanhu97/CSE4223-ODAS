{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandasToMatrix\n",
    "### Sumarry\n",
    "pandas to matrix accepts a date (##-##-20##), starting hour, total number of hours, and multiple source indicator as its parameters. pandasToMatrix will take the dataframes given these parameters and return a 13 dimensional matrix that represents the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_matching_single(dfs):\n",
    "    \n",
    "    # we drop multiple entries with the same time and microphone number, since these are obvious duplicates\n",
    "    df = dfs.drop_duplicates(subset=['Time In Seconds', 'Microphone Number'])\n",
    "\n",
    "    master_list = []\n",
    "    # call the first entry of the 'Time In Seconds' column 'start_time'\n",
    "    start_time = df['Time In Seconds'][0]\n",
    "    split = start_time + 0.0077\n",
    "    \n",
    "    # call the last entry of the 'Time In Seconds' column 'end_time'\n",
    "    end_time = df['Time In Seconds'].iloc[-1]\n",
    "    \n",
    "    temp = df.iloc[0] # saving first entry of the data frame in temp\n",
    "    \n",
    "    # setting the coordinates of the first entry to None\n",
    "    temp['X'] = None \n",
    "    temp['Y'] = None\n",
    "    temp['Z'] = None\n",
    "    temp['Microphone Number'] = None\n",
    "    \n",
    "    # Generating one copy of temp for each mic_array. The attributes apart from X,Y,Z and array_number are intact\n",
    "    array_0 = temp\n",
    "    array_1 = temp\n",
    "    array_2 = temp\n",
    "    array_3 = temp\n",
    "    \n",
    "    \n",
    "    counter = 0 #?\n",
    "    #Assuming only 1 channel for each array\n",
    "    \n",
    "    for row in df.iterrows():\n",
    "        if row[1]['Time In Seconds'] >= split:\n",
    "#             print('ok')\n",
    "            data_point = [None] * 13           # list with 13 None values\n",
    "            data_point[0] = array_0['X']\n",
    "            data_point[1] = array_0['Y']\n",
    "            data_point[2] = array_0['Z']\n",
    "            data_point[3] = array_1['X']\n",
    "            data_point[4] = array_1['Y']\n",
    "            data_point[5] = array_1['Z']\n",
    "            data_point[6] = array_2['X']\n",
    "            data_point[7] = array_2['Y']\n",
    "            data_point[8] = array_2['Z']\n",
    "            data_point[9] = array_3['X']\n",
    "            data_point[10] = array_3['Y']\n",
    "            data_point[11] = array_3['Z']\n",
    "            data_point[12] = split - .0077\n",
    "            \n",
    "            if data_point[0] != None  or data_point[3] != None or  data_point[6] != None or data_point[9] != None:\n",
    "#                 print('hey')\n",
    "#                 print(data_point)\n",
    "                master_list.append(data_point)\n",
    "            filler = copy.copy(row[1])\n",
    "            filler['X'] = None\n",
    "            filler['Y'] = None\n",
    "            filler['Z'] = None\n",
    "            array_0 = filler\n",
    "            array_1 = filler\n",
    "            array_2 = filler\n",
    "            array_3 = filler\n",
    "            \n",
    "            split = row[1]['Time In Seconds'] + 0.0077\n",
    "\n",
    "            \n",
    "                \n",
    "        if row[1]['Microphone Number'] == 0:\n",
    "            array_0 = row[1]\n",
    "            \n",
    "        elif row[1]['Microphone Number'] == 1:\n",
    "            array_1 = row[1]\n",
    "            \n",
    "        elif row[1]['Microphone Number'] == 2:\n",
    "            array_2 = row[1]\n",
    "\n",
    "        else:\n",
    "            array_3 = row[1]\n",
    "#     print(master_list) # master_list is being formed correctly\n",
    "    return master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "a = [None] * 13\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_contiguous_hours_extractor(date, path):\n",
    "    list_dir = os.listdir(path)\n",
    "    list_dir_nums = []\n",
    "    for i in list_dir:\n",
    "        list_dir_nums.append(int(i[:-4]))\n",
    "    list_dir_nums.sort()\n",
    "    return list_dir_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(date, starting_hour=1, num_hours=1, multiple_sources=False):\n",
    "    \"\"\" Given the date, starting hour, and number of hours, this function processes combined csv\n",
    "    files on the ODAS google drive folder and gives the corresponding matrix as the output.\"\"\"\n",
    "    \n",
    "    # which .csv file to process? -> the one given in the date parameter\n",
    "    date_path_combined = '/home/ardelalegre/google-drive/ODAS/dataframes/combined/'+ date\n",
    "    \n",
    "    # in the date folder, combined .csv files are arranged according to the hour when they were recorded\n",
    "    \n",
    "    # we have observed that .csv files are not present for every hour, so right now, we will process\n",
    "    # the .csv file for every hour instead of doing so for a subset of hours.\n",
    "    \n",
    "    # earlier, Ardel had written a main function with additional parameters starting_hour and num_hours.\n",
    "    # We are keeping the additional parameters but they do not affect the code as of now.\n",
    "    # Below is his code we are temporarily commenting out.\n",
    "    \n",
    "    \n",
    "    matricies = []\n",
    "    \n",
    "    # Ardel's code begins\n",
    "#     ending_hour = starting_hour + num_hours\n",
    "#     if(ending_hour >= 25):\n",
    "#         print(\"Hours must end before end of day.\")\n",
    "#         return\n",
    "    # Ardel's code ends\n",
    "    \n",
    "    \n",
    "    # right now, we are just listing all the hours for which a combined .csv exists.\n",
    "    # non_contiguous_hours returns a list of integers corresponding to such hours\n",
    "    hours_ints = non_contiguous_hours_extractor(date,date_path_combined)\n",
    "    \n",
    "    \n",
    "    # we convert the list of ints to a list of strings that exactly match the hour file names\n",
    "    # we store the list in 'hours'\n",
    "    hours = []\n",
    "    \n",
    "    for i in hours_ints:\n",
    "        if(i > 9):\n",
    "            hours.append(str(i))\n",
    "        else:\n",
    "            hours.append('0' + str(i))\n",
    "\n",
    "    # each hour directory contains one combined .csv file with the name\n",
    "    # \"/home/ardelalegre/google-drive/ODAS/dataframes/combined/yyyy-mm-dd/hh.csv\"\n",
    "    # In the following code, we read each file and pass it to 'source_matching_single()'\n",
    "    # the .csv is being read correctly\n",
    "    for hour in hours:\n",
    "        df = pd.read_csv(date_path_combined+'/' + str(hour) + '.csv')\n",
    "        if(multiple_sources):\n",
    "            pass\n",
    "        else:\n",
    "#             print(df)\n",
    "            temp = source_matching_single(df) # earlier convert_single\n",
    "#             print(temp)\n",
    "#         try:\n",
    "        # temp is a list of lists. If we loop through each element and convert it into an nparray\n",
    "        temp_np_arr = np.asarray([np.asarray(i) for i in temp])\n",
    "        matricies.append(temp)\n",
    "#         except:\n",
    "#             print(\"Too many hours\")\n",
    "    return matricies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardelalegre/.local/lib/python3.5/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ardelalegre/.local/lib/python3.5/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ardelalegre/.local/lib/python3.5/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/ardelalegre/.local/lib/python3.5/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "date = '2019-09-14'\n",
    "test_matrix = main('2019-09-14')\n",
    "# test_matrix is a nested list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_matrix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pandasToMatrix.py\n"
     ]
    }
   ],
   "source": [
    "# %%writefile pandasToMatrix.py\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import copy\n",
    "# import os\n",
    "\n",
    "# def source_matching_single(dfs):\n",
    "    \n",
    "#     # we drop multiple entries with the same time and microphone number, since these are obvious duplicates\n",
    "#     df = dfs.drop_duplicates(subset=['Time In Seconds', 'Microphone Number'])\n",
    "\n",
    "#     master_list = []\n",
    "#     # call the first entry of the 'Time In Seconds' column 'start_time'\n",
    "#     start_time = df['Time In Seconds'][0]\n",
    "#     split = start_time + 0.0077\n",
    "    \n",
    "#     # call the last entry of the 'Time In Seconds' column 'end_time'\n",
    "#     end_time = df['Time In Seconds'].iloc[-1]\n",
    "    \n",
    "#     temp = df.iloc[0] # saving first entry of the data frame in temp\n",
    "    \n",
    "#     # setting the coordinates of the first entry to None\n",
    "#     temp['X'] = None \n",
    "#     temp['Y'] = None\n",
    "#     temp['Z'] = None\n",
    "#     temp['Microphone Number'] = None\n",
    "    \n",
    "#     # Generating one copy of temp for each mic_array. The attributes apart from X,Y,Z and array_number are intact\n",
    "#     array_0 = temp\n",
    "#     array_1 = temp\n",
    "#     array_2 = temp\n",
    "#     array_3 = temp\n",
    "    \n",
    "    \n",
    "#     counter = 0 #?\n",
    "#     #Assuming only 1 channel for each array\n",
    "    \n",
    "#     for row in df.iterrows():\n",
    "#         if row[1]['Time In Seconds'] >= split:\n",
    "# #             print('ok')\n",
    "#             data_point = [None] * 13           # list with 13 None values\n",
    "#             data_point[0] = array_0['X']\n",
    "#             data_point[1] = array_0['Y']\n",
    "#             data_point[2] = array_0['Z']\n",
    "#             data_point[3] = array_1['X']\n",
    "#             data_point[4] = array_1['Y']\n",
    "#             data_point[5] = array_1['Z']\n",
    "#             data_point[6] = array_2['X']\n",
    "#             data_point[7] = array_2['Y']\n",
    "#             data_point[8] = array_2['Z']\n",
    "#             data_point[9] = array_3['X']\n",
    "#             data_point[10] = array_3['Y']\n",
    "#             data_point[11] = array_3['Z']\n",
    "#             data_point[12] = split - .0077\n",
    "            \n",
    "#             if data_point[0] != None  or data_point[3] != None or  data_point[6] != None or data_point[9] != None:\n",
    "# #                 print('hey')\n",
    "# #                 print(data_point)\n",
    "#                 master_list.append(data_point)\n",
    "#             filler = copy.copy(row[1])\n",
    "#             filler['X'] = None\n",
    "#             filler['Y'] = None\n",
    "#             filler['Z'] = None\n",
    "#             array_0 = filler\n",
    "#             array_1 = filler\n",
    "#             array_2 = filler\n",
    "#             array_3 = filler\n",
    "            \n",
    "#             split = row[1]['Time In Seconds'] + 0.0077\n",
    "\n",
    "            \n",
    "                \n",
    "#         if row[1]['Microphone Number'] == 0:\n",
    "#             array_0 = row[1]\n",
    "            \n",
    "#         elif row[1]['Microphone Number'] == 1:\n",
    "#             array_1 = row[1]\n",
    "            \n",
    "#         elif row[1]['Microphone Number'] == 2:\n",
    "#             array_2 = row[1]\n",
    "\n",
    "#         else:\n",
    "#             array_3 = row[1]\n",
    "# #     print(master_list) # master_list is being formed correctly\n",
    "#     return master_list\n",
    "\n",
    "\n",
    "# def non_contiguous_hours_extractor(date, path):\n",
    "#     list_dir = os.listdir(path)\n",
    "#     list_dir_nums = []\n",
    "#     for i in list_dir:\n",
    "#         list_dir_nums.append(int(i[:-4]))\n",
    "#     list_dir_nums.sort()\n",
    "#     return list_dir_nums\n",
    "\n",
    "\n",
    "# def main(date, starting_hour=1, num_hours=1, multiple_sources=False):\n",
    "#     \"\"\" Given the date, starting hour, and number of hours, this function processes combined csv\n",
    "#     files on the ODAS google drive folder and gives the corresponding matrix as the output.\"\"\"\n",
    "    \n",
    "#     # which .csv file to process? -> the one given in the date parameter\n",
    "#     date_path_combined = '/home/ardelalegre/google-drive/ODAS/dataframes/combined/'+ date\n",
    "    \n",
    "#     # in the date folder, combined .csv files are arranged according to the hour when they were recorded\n",
    "    \n",
    "#     # we have observed that .csv files are not present for every hour, so right now, we will process\n",
    "#     # the .csv file for every hour instead of doing so for a subset of hours.\n",
    "    \n",
    "#     # earlier, Ardel had written a main function with additional parameters starting_hour and num_hours.\n",
    "#     # We are keeping the additional parameters but they do not affect the code as of now.\n",
    "#     # Below is his code we are temporarily commenting out.\n",
    "    \n",
    "    \n",
    "#     matricies = []\n",
    "    \n",
    "#     # Ardel's code begins\n",
    "# #     ending_hour = starting_hour + num_hours\n",
    "# #     if(ending_hour >= 25):\n",
    "# #         print(\"Hours must end before end of day.\")\n",
    "# #         return\n",
    "#     # Ardel's code ends\n",
    "    \n",
    "    \n",
    "#     # right now, we are just listing all the hours for which a combined .csv exists.\n",
    "#     # non_contiguous_hours returns a list of integers corresponding to such hours\n",
    "#     hours_ints = non_contiguous_hours_extractor(date,date_path_combined)\n",
    "    \n",
    "    \n",
    "#     # we convert the list of ints to a list of strings that exactly match the hour file names\n",
    "#     # we store the list in 'hours'\n",
    "#     hours = []\n",
    "    \n",
    "#     for i in hours_ints:\n",
    "#         if(i > 9):\n",
    "#             hours.append(str(i))\n",
    "#         else:\n",
    "#             hours.append('0' + str(i))\n",
    "\n",
    "#     # each hour directory contains one combined .csv file with the name\n",
    "#     # \"/home/ardelalegre/google-drive/ODAS/dataframes/combined/yyyy-mm-dd/hh.csv\"\n",
    "#     # In the following code, we read each file and pass it to 'source_matching_single()'\n",
    "#     # the .csv is being read correctly\n",
    "#     for hour in hours:\n",
    "#         df = pd.read_csv(date_path_combined+'/' + str(hour) + '.csv')\n",
    "#         if(multiple_sources):\n",
    "#             pass\n",
    "#         else:\n",
    "# #             print(df)\n",
    "#             temp = source_matching_single(df) # earlier convert_single\n",
    "# #             print(temp)\n",
    "# #         try:\n",
    "#         # temp is a list of lists. If we loop through each element and convert it into an nparray\n",
    "#         temp_np_arr = np.asarray([np.asarray(i) for i in temp])\n",
    "#         matricies.append(temp)\n",
    "# #         except:\n",
    "# #             print(\"Too many hours\")\n",
    "#     return matricies\n",
    "\n",
    "# date = '2019-09-14'\n",
    "# test_matrix = main('2019-09-14')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
