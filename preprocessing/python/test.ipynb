{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re \n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "# Extract time information of each recording from the log file\n",
    "def timeExtract(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Start counting from the last byte\n",
    "        counter = 1\n",
    "        # Go to the 2nd byte before the end of the last line\n",
    "        f.seek(-2, 2) \n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "            counter=counter+1\n",
    "        endTime_line = f.readline().decode()\n",
    "        # Go to the 2nd byte before the end of the last second line\n",
    "        f.seek(-counter-2, 2)\n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "        startTime_line = f.readline().decode()\n",
    "\n",
    "    return [startTime_line, endTime_line]\n",
    "\n",
    "# Calculate duration of each recording in microseconds\n",
    "def durationinMicroseconds(filename):\n",
    "    startTime = timeExtract(filename)[0].split()[2:]\n",
    "    endTime = timeExtract(filename)[1].split()[2:]\n",
    "    startTimeStr = startTime[0] + ' ' + startTime[1]\n",
    "    endTimeStr = endTime[0] + ' ' + endTime[1]\n",
    "    T1 = datetime.datetime.strptime(startTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    T2 = datetime.datetime.strptime(endTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    delta = T2-T1\n",
    "    duration = delta.seconds*1000000 + delta.microseconds\n",
    "    \n",
    "    return duration, T1, T2\n",
    "\n",
    "# Converts .log files into pandas dataframes\n",
    "def extractDirectionalities(filename, mic_number):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Use repex to store blocks of data into a list\n",
    "    data = re.split('(?<=})\\n(?={)', text) \n",
    "        # Delete the time info from the last data block\n",
    "    tmp = data[-1][:(data[-1].rfind(\"}\")+1)]\n",
    "    data[-1] = tmp\n",
    "        \n",
    "    #list of src blocks \n",
    "\n",
    "    srcList = [json.loads(block)[\"src\"] for block in data]\n",
    "\n",
    "    \n",
    "    #initialize dataframe to have colums: timestamp, time, data inside source\n",
    "    #timestamp is the initial time stamp\n",
    "    #time is the datetime value converted from the timestamp and intitial time\n",
    "    #source is a 4 by 6 array where the rows are the source, and the columns are the source values\n",
    "    df = pd.DataFrame(columns = ['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'Source ID', 'X', 'Y', 'Z', 'Activity'])\n",
    "    \n",
    "    #Used for calculating timestamps -> time\n",
    "    duration, startTime, endTime = durationinMicroseconds(filename)\n",
    "    start_time_in_seconds = time.mktime(startTime.timetuple())\n",
    "    t = duration/len(data) / 1000000.0\n",
    "    \n",
    "    index = 1.0\n",
    "    ind = 0\n",
    "    df_dict = {}\n",
    "    for block in srcList:\n",
    "        if block[0][\"id\"] != 0 or block[1][\"id\"] != 0 or block[2][\"id\"] != 0 or block[3][\"id\"] != 0:\n",
    "            time_in_seconds = start_time_in_seconds + (index - 1.0) * t\n",
    "            for i in range(0, 4):\n",
    "                if block[i]['id'] != 0:\n",
    "                    df_dict[ind] = {\"Timestamp\": [index], \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}\n",
    "                    ind = ind + 1\n",
    "                    #df = df.append(pd.DataFrame({\"Timestamp\": [index], \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}, index=[0]))\n",
    "        index = index + 1.0\n",
    "    \n",
    "    df = df.append(pd.DataFrame.from_dict(df_dict,\"index\"))\n",
    "    return(df)\n",
    "\n",
    "#Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution of processAllLogs_new.py started at 2020-07-14 11:44:18.807665\n",
      "Now processing logs0\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/dataframes/dataframes0/2020-07-14/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardelalegre/.local/lib/python3.5/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making directory: /home/ardelalegre/google-drive/ODAS/dataframes/dataframes0/2020-07-14/11\n",
      "making directory: /h\n",
      "Could not process file: /home/ardelalegre/google-drive/ODAS/logs0/SST/cSST_2020-07-09_16:45:04_0.log\n",
      "Could not process file: /home/ardelalegre/google-drive/ODAS/logs0/SST/cSST_2020-07-09_16:50:04_0.log\n",
      "Could not process file: /home/ardelalegre/google-drive/ODAS/logs0/SST/cSST_2020-07-09_16:55:04_0.log\n",
      "Could not process file: /home/ardelalegre/google-drive/ODAS/logs0/SST/cSST_2020-07-09_17:00:04_0.log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/dataframes/dataframes0/2020-07-10/11\n",
      "Now processing logs1\n",
      "Could not process file: /home/ardelalegre/google-drive/ODAS/logs1/SST/cSST_2020-06-26_13:00:12_1.log\n",
      "making directory: /h\n",
      "Now processing logs2\n",
      "Now processing logs3\n",
      "Execution of processAllLogs_new.py ended at 2020-07-14 12:01:59.872420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Execution of processAllLogs_new.py started at \" + str(datetime.datetime.now()))\n",
    "\n",
    "records0 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs0/SST/*.log')\n",
    "records1 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs1/SST/*.log')\n",
    "records2 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs2/SST/*.log')\n",
    "records3 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs3/SST/*.log')\n",
    "\n",
    "records = [records0, records1, records2, records3]\n",
    "\n",
    "for mic_number in range(len(records)):\n",
    "    \n",
    "    destination = \"/home/ardelalegre/google-drive/ODAS/logs\" + str(mic_number) + \"/SST/Processed\"\n",
    "    print(\"Now processing logs\" + str(mic_number))\n",
    "    \n",
    "    for log in records[mic_number]:\n",
    "        \n",
    "        with open(log, 'r') as f:\n",
    "                firstline = f.readline()\n",
    "                if firstline == \"SST log contains no useful data\\n\":\n",
    "                    try:\n",
    "                        temp = shutil.move(log,destination) # new\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "                    continue\n",
    "                    \n",
    "        log_string = log[:-6] + '.log' # modification to account for added array number to path\n",
    "#         print(log_string)\n",
    "        \n",
    "        hour = log_string[log_string.rfind('_') + 1: log_string.rfind('_') + 1 + 2]\n",
    "        day = log_string[log_string.find('_') + 1: log_string.rfind('_')]\n",
    "        path = log_string[:log_string.find('S/') + 2] + 'dataframes/dataframes' + str(mic_number) + '/'\n",
    "#         print(path)\n",
    "#         print(day)\n",
    "#         print(hour)\n",
    "        try:\n",
    "            if(not os.path.isdir(os.path.join(path, day))):\n",
    "                os.mkdir(os.path.join(path, day))\n",
    "            \n",
    "            path = os.path.join(path, day, hour)\n",
    "            if(not os.path.isdir(path)):\n",
    "                print(\"making directory: \" + str(path))\n",
    "                os.mkdir(path)\n",
    "        \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "#         print(path)\n",
    "        try:\n",
    "            df = extractDirectionalities(log, mic_number)\n",
    "            if(not os.path.isdir(path)):\n",
    "                os.mkdir(path)\n",
    "            df.to_csv(path_or_buf=path+ '/' + log[log.find('_') + 1:log.find('.')]+'.csv', index=False)\n",
    "            temp = shutil.move(log,destination) # new\n",
    "        except:\n",
    "            print('Could not process file: ' + log)\n",
    "        \n",
    "        \n",
    "print(\"Execution of processAllLogs_new.py ended at \" + str(datetime.datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = a - datetime.timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-08 16:20:28.139943'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(yesterday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
