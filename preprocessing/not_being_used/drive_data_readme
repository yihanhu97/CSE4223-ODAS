This file explains:
1. How data is organized on google drive
2. What permissions are needed to run the scripts


Data Organization on Google Drive

Drive link: https://drive.google.com/drive/u/1/folders/1dM7PO96C1XKXNNycvZ8HKhXWvptIHryh

A. Log files: 
cSST_yyyy-mm-dd-hh-mm-ss_device.log

device indicates array number, could be 0, 1, 2, 3

Each mic. array in the ODAS system generates logs files.
A log is a data structure that contains info like:
	a. number of sound sources detected (max 4)
	b. intensity of each sound source
	c. x, y, and z coordinates of each source
	d. source id (this is useful for tracking)
	e. tag (when the source is moving, the tag is set to 'dynamic')
	f. timestamp
Each log file is associated with a start time. The log file is named according to this start time.


Log files are organized into folders based on which mic. array generates them.
For example, the folder 'logs0' contains log files generated by mic. array 0, and so on.

B. /ODAS/dataframes

The script processAllLogs.py converts each log file into a .csv file.
These .csv files are first organised based on which mic array generated them, and then on what date they were generated on.

C. /ODAS/dataframes/combined

The code titled 'Combine all dataframes per hour' at the end of the notebook logsToDataframes.ipynb creates one .csv file for each hour of data recorded. It uses the .csv files generated by processAllLogs.py.
The resulting .csv files are found in /ODAS/dataframes/combined. They are organized according to date.

The stage is then set to convert the combined .csv files into a data matrix.


Scripts:

The following are the scripts that help in converting the logs into a numpy array with positions and time stamps:

1. 'processAllLogs.py':-
	Input: Log files
	Output: a corresponding .csv file for each log file
	

2. 'combineDataframes.py'
	Input: .csv files from all mic arrays
	Ouput: a combined .csv file with entries from all arrays

3. (pandasToMatrix.ipynb)/ 'pivot_12_entry_row.py': Generates a combined .csv file with separate columns for each array.

4. processManagement.py : check for new files and process them (called from cron tab).









 



