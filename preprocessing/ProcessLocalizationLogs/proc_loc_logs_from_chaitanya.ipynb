{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Extract time information of each recording from the log file\n",
    "def timeExtract(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Start counting from the last byte\n",
    "        counter = 1\n",
    "        # Go to the 2nd byte before the end of the last line\n",
    "        f.seek(-2, 2)\n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "            counter = counter + 1\n",
    "        endTime_line = f.readline().decode()\n",
    "        # Go to the 2nd byte before the end of the last second line\n",
    "        f.seek(-counter - 2, 2)\n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "        startTime_line = f.readline().decode()\n",
    "\n",
    "    return [startTime_line, endTime_line]\n",
    "\n",
    "\n",
    "# Calculate duration of each recording in microseconds\n",
    "def durationinMicroseconds(filename):\n",
    "    startTime = timeExtract(filename)[0].split()[2:]\n",
    "    endTime = timeExtract(filename)[1].split()[2:]\n",
    "    startTimeStr = startTime[0] + ' ' + startTime[1]\n",
    "    endTimeStr = endTime[0] + ' ' + endTime[1]\n",
    "    T1 = datetime.datetime.strptime(startTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    T2 = datetime.datetime.strptime(endTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    delta = T2 - T1\n",
    "    duration = delta.seconds * 1000000 + delta.microseconds\n",
    "\n",
    "    return duration, T1, T2\n",
    "\n",
    "\n",
    "# Converts .log files into pandas dataframes\n",
    "def extractDirectionalities(filename, mic_number):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Use repex to store blocks of data into a list\n",
    "    data = re.split('(?<=})\\n(?={)', text)\n",
    "    # Delete the time info from the last data block\n",
    "    tmp = data[-1][:(data[-1].rfind(\"}\") + 1)]\n",
    "    data[-1] = tmp\n",
    "\n",
    "    # list of src blocks\n",
    "\n",
    "    srcList = [json.loads(block)[\"src\"] for block in data]\n",
    "\n",
    "    # initialize dataframe to have colums: timestamp, time, data inside source\n",
    "    # timestamp is the initial time stamp\n",
    "    # time is the datetime value converted from the timestamp and intitial time\n",
    "    # source is a 4 by 6 array where the rows are the source, and the columns are the source values\n",
    "    df = pd.DataFrame(\n",
    "        columns=['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'X', 'Y', 'Z', 'E'])\n",
    "\n",
    "    # Used for calculating timestamps -> time\n",
    "    duration, startTime, endTime = durationinMicroseconds(filename)\n",
    "    start_time_in_seconds = time.mktime(startTime.timetuple())\n",
    "    t = duration / len(data) / 1000000.0\n",
    "\n",
    "    index = 1.0\n",
    "    ind = 0\n",
    "    df_dict = {}\n",
    "    for block in srcList:\n",
    "        if block[0][\"E\"] != 0 or block[1][\"E\"] != 0 or block[2][\"E\"] != 0 or block[3][\"E\"] != 0: # if all four source ids are not 0, process\n",
    "            time_in_seconds = start_time_in_seconds + (index - 1.0) * t\n",
    "            for i in range(0, 4):\n",
    "                if block[i]['E'] != 0:\n",
    "                    df_dict[ind] = {\"Timestamp\": [index],\n",
    "                                    \"Time\": datetime.datetime.fromtimestamp(time_in_seconds).strftime(\n",
    "                                        \"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds,\n",
    "                                    \"Microphone Number\": mic_number, \"X\": block[i][\"x\"],\n",
    "                                    \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"E\": block[i][\"E\"]}\n",
    "                    ind = ind + 1\n",
    "                    # df = df.append(pd.DataFrame({\"Timestamp\": [index], \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}, index=[0]))\n",
    "        index = index + 1.0\n",
    "\n",
    "    df = df.append(pd.DataFrame.from_dict(df_dict, \"index\"))\n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution of processAllLogs_new_local.py started at 2020-08-04 11:38:07.836421\n",
      "Now processing logs0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardelalegre/.local/lib/python3.5/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Now processing logs1\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/10\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/13\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/11\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/20\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/17\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/14\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/15\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/19\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/12\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/18\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/16\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes1/2020-07-31/09\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Now processing logs2\n",
      "Now processing logs3\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/16\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/12\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/10\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/14\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/11\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/15\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/13\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "making directory: /home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes3/2020-07-31/18\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n",
      "Just processed a log\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Main\n",
    "\n",
    "print(\"Execution of processLocalizationLogs.py started at \" + str(datetime.datetime.now()))\n",
    "\n",
    "# Selecting files to process\n",
    "\n",
    "records0  = glob.glob('/home/ardelalegre/google-drive/ODAS/logs0/SSL/cSSL_2020-07-31_*.log')\n",
    "records1  = glob.glob('/home/ardelalegre/google-drive/ODAS/logs1/SSL/cSSL_2020-07-31_*.log')\n",
    "records2  = glob.glob('/home/ardelalegre/google-drive/ODAS/logs2/SSL/cSSL_2020-07-31_*.log')\n",
    "records3  = glob.glob('/home/ardelalegre/google-drive/ODAS/logs3/SSL/cSSL_2020-07-31_*.log')\n",
    "\n",
    "\n",
    "records = [records0, records1, records2, records3]\n",
    "\n",
    "# Processing selected files\n",
    "\n",
    "for mic_number in range(len(records)):\n",
    "\n",
    "    destination = \"/home/ardelalegre/google-drive/ODAS/logs\" + str(mic_number) + \"/SSL/Processed\"\n",
    "    if(not os.path.isdir(destination)):\n",
    "        os.makedirs(destination)\n",
    "    print(\"Now processing localization logs\" + str(mic_number))\n",
    "    for log in records[mic_number]:\n",
    "        with open(log, 'r') as f:\n",
    "            firstline = f.readline()\n",
    "            if firstline == \"SSL log contains no useful data\\n\":\n",
    "                try:\n",
    "                    temp = shutil.move(log, destination)  # new\n",
    "                except:\n",
    "                    continue\n",
    "                continue\n",
    "\n",
    "        log_string = log[:-6] + '.log'  # modification to account for added array number to path\n",
    "        #         print(log_string)\n",
    "\n",
    "        hour = log_string[log_string.rfind('_') + 1: log_string.rfind('_') + 1 + 2]\n",
    "        day = log_string[log_string.find('_') + 1: log_string.rfind('_')]\n",
    "        path = log_string[:log_string.find('S/') + 2] + 'localization_dataframes/dataframes' + str(mic_number) + '/' # ardelalegre modified ardel's code\n",
    "        #         print(path)\n",
    "        #         print(day)\n",
    "        #         print(hour)\n",
    "\n",
    "        if (not os.path.isdir(os.path.join(path, day))):\n",
    "            os.makedirs(os.path.join(path, day))\n",
    "\n",
    "        path = os.path.join(path, day, hour)\n",
    "        if (not os.path.isdir(path)):\n",
    "            print(\"making directory: \" + str(path))\n",
    "            os.mkdir(path)\n",
    "\n",
    "        #         print(path)\n",
    "        try:\n",
    "            df = extractDirectionalities(log, mic_number)\n",
    "            if (not os.path.isdir(path)):\n",
    "                os.mkdir(path)\n",
    "            df.to_csv(path_or_buf=path + '/' + log[log.find('_') + 1:log.find('.')] + '.csv', index=False)\n",
    "            temp = shutil.move(log, destination)  # new\n",
    "            print(\"Just processed a log\")\n",
    "        except:\n",
    "            print('Could not process file: ' + log)\n",
    "\n",
    "print(\"Execution of processLocalizationLogs.py ended at \" + str(datetime.datetime.now()))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
