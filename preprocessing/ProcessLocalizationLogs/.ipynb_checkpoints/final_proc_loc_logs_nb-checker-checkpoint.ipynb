{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution of processAllLogs_new.py started at 2020-08-03 16:38:23.071967\n",
      "Now processing logs0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re \n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "# Extract time information of each recording from the log file\n",
    "def timeExtract(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Start counting from the last byte\n",
    "        counter = 1\n",
    "        # Go to the 2nd byte before the end of the last line\n",
    "        f.seek(-2, 2) \n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "            counter=counter+1\n",
    "        endTime_line = f.readline().decode()\n",
    "        # Go to the 2nd byte before the end of the last second line\n",
    "        f.seek(-counter-2, 2)\n",
    "        while f.read(1) != b'\\n':\n",
    "            f.seek(-2, 1)\n",
    "        startTime_line = f.readline().decode()\n",
    "\n",
    "    return [startTime_line, endTime_line]\n",
    "\n",
    "# Calculate duration of each recording in microseconds\n",
    "def durationinMicroseconds(filename):\n",
    "    startTime = timeExtract(filename)[0].split()[2:]\n",
    "    endTime = timeExtract(filename)[1].split()[2:]\n",
    "    startTimeStr = startTime[0] + ' ' + startTime[1]\n",
    "    endTimeStr = endTime[0] + ' ' + endTime[1]\n",
    "    T1 = datetime.datetime.strptime(startTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    T2 = datetime.datetime.strptime(endTimeStr, '%Y-%m-%d %H:%M:%S.%f')\n",
    "    delta = T2-T1\n",
    "    duration = delta.seconds*1000000 + delta.microseconds\n",
    "    \n",
    "    return duration, T1, T2\n",
    "\n",
    "\n",
    "# Converts .log files into pandas dataframes\n",
    "def extractDirectionalities(filename, mic_number):\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Use repex to store blocks of data into a list\n",
    "    data = re.split('(?<=})\\n(?={)', text)\n",
    "    # Delete the time info from the last data block\n",
    "    tmp = data[-1][:(data[-1].rfind(\"}\") + 1)]\n",
    "    data[-1] = tmp\n",
    "\n",
    "    # list of src blocks\n",
    "\n",
    "    srcList = [json.loads(block)[\"src\"] for block in data]\n",
    "\n",
    "    # initialize dataframe to have colums: timestamp, time, data inside source\n",
    "    # timestamp is the initial time stamp\n",
    "    # time is the datetime value converted from the timestamp and intitial time\n",
    "    # source is a 4 by 6 array where the rows are the source, and the columns are the source values\n",
    "    df = pd.DataFrame(\n",
    "        columns=['Timestamp', 'Time', 'Time In Seconds', 'Microphone Number', 'X', 'Y', 'Z', 'E'])\n",
    "\n",
    "    # Used for calculating timestamps -> time\n",
    "    duration, startTime, endTime = durationinMicroseconds(filename)\n",
    "    start_time_in_seconds = time.mktime(startTime.timetuple())\n",
    "    t = duration / len(data) / 1000000.0\n",
    "\n",
    "    index = 1.0\n",
    "    ind = 0\n",
    "    df_dict = {}\n",
    "    for block in srcList:\n",
    "        if block[0][\"E\"] != 0 or block[1][\"E\"] != 0 or block[2][\"E\"] != 0 or block[3][\"E\"] != 0: # if all four source ids are not 0, process\n",
    "            time_in_seconds = start_time_in_seconds + (index - 1.0) * t\n",
    "            for i in range(0, 4):\n",
    "                if block[i]['E'] != 0:\n",
    "                    df_dict[ind] = {\"Timestamp\": [index],\n",
    "                                    \"Time\": datetime.datetime.fromtimestamp(time_in_seconds).strftime(\n",
    "                                        \"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds,\n",
    "                                    \"Microphone Number\": mic_number, \"X\": block[i][\"x\"],\n",
    "                                    \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"E\": block[i][\"E\"]}\n",
    "                    ind = ind + 1\n",
    "                    # df = df.append(pd.DataFrame({\"Timestamp\": [index], \"Time\":datetime.datetime.fromtimestamp(time_in_seconds).strftime(\"%A, %B %d, %Y %I:%M:%S\"), \"Time In Seconds\": time_in_seconds, \"Microphone Number\":mic_number, \"Source ID\": block[i][\"id\"], \"X\": block[i][\"x\"], \"Y\": block[i][\"y\"], \"Z\": block[i][\"z\"], \"Activity\": block[i][\"activity\"]}, index=[0]))\n",
    "        index = index + 1.0\n",
    "\n",
    "    df = df.append(pd.DataFrame.from_dict(df_dict, \"index\"))\n",
    "    return (df)\n",
    "\n",
    "\n",
    "#Main\n",
    "\n",
    "print(\"Execution of processAllLogs_new.py started at \" + str(datetime.datetime.now()))\n",
    "\n",
    "records0 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs0/SSL/cSSL_2020-07-31_*.log')\n",
    "records1 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs1/SSL/cSSL_2020-07-31_*.log')\n",
    "records2 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs2/SSL/cSSL_2020-07-31_*.log')\n",
    "records3 = glob.glob('/home/ardelalegre/google-drive/ODAS/logs3/SSL/cSSL_2020-07-31_*.log')\n",
    "\n",
    "records = [records0, records1, records2, records3]\n",
    "\n",
    "\n",
    "for mic_number in range(len(records)):\n",
    "    \n",
    "    destination = \"/home/ardelalegre/google-drive/ODAS/logs\" + str(mic_number) + \"/SSL/Processed\"\n",
    "    print(\"Now processing logs\" + str(mic_number))\n",
    "    \n",
    "    for log in records[mic_number]:\n",
    "        try:\n",
    "            with open(log, 'r') as f:\n",
    "                    firstline = f.readline()\n",
    "                    if firstline == \"SSL log contains no useful data\\n\":\n",
    "                        try:\n",
    "                            temp = shutil.move(log,destination) # new\n",
    "                        except:\n",
    "                            continue\n",
    "                        continue\n",
    "\n",
    "            log_string = log[:-6] + '.log' # modification to account for added array number to path\n",
    "    #         print(log_string)\n",
    "\n",
    "            hour = log_string[log_string.rfind('_') + 1: log_string.rfind('_') + 1 + 2]\n",
    "            day = log_string[log_string.find('_') + 1: log_string.rfind('_')]\n",
    "            path = log_string[:log_string.find('S/') + 2] + 'localization_dataframes/dataframes' + str(mic_number) + '/'\n",
    "    #         print(path)\n",
    "    #         print(day)\n",
    "    #         print(hour)\n",
    "            try:\n",
    "                if(not os.path.isdir(os.path.join(path, day))):\n",
    "                    os.makedirs(os.path.join(path, day))\n",
    "\n",
    "                path = os.path.join(path, day, hour)\n",
    "                if(not os.path.isdir(path)):\n",
    "                    print(\"making directory: \" + str(path))\n",
    "                    os.makedirs(path)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    #         print(path)\n",
    "            try:\n",
    "                df = extractDirectionalities(log, mic_number)\n",
    "                if(not os.path.isdir(path)):\n",
    "                    os.makedirs(path)\n",
    "                df.to_csv(path_or_buf=path+ '/' + log[log.find('_') + 1:log.find('.')]+'.csv', index=False)\n",
    "                try:\n",
    "                    temp = shutil.move(log,destination) # new\n",
    "                except:\n",
    "                    continue\n",
    "            except:\n",
    "                print('Could not process file: ' + log)\n",
    "        except:\n",
    "            print('Could not open file: ' + log)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "print(\"Execution of processAllLogs_new.py ended at \" + str(datetime.datetime.now()))\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script combines dataframes from all microphone arrays produced one day ago relative to the date when the script is run\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "#define the dates and hours to be combined\n",
    "\n",
    "today = datetime.datetime.now() # extract todays date\n",
    "a = today - datetime.timedelta(days = 1) # extract yesterday's date\n",
    "\n",
    "a = str(a) # convert into string\n",
    "year = a[:4] # extract yesterday's year\n",
    "month = a[5:7] # extract yesterday's month\n",
    "day = a[8:10] # extract yesterday\n",
    "\n",
    "\n",
    "hours = []\n",
    "for i in range(10):\n",
    "    hours.append('0' + str(i))\n",
    "for i in range(10, 25):\n",
    "    hours.append(str(i))\n",
    "\n",
    "#iterate through dates and combine. Then for each hour, for each array if a directory exists for that hour, list all the csv files for that hour. Read them and append \n",
    "\n",
    "date = year + '-' + month + '-' + day # setting date to yesterdays date\n",
    "date_path = os.path.join('/home/ardelalegre/google-drive/ODAS/localization_dataframes/combined/', date)\n",
    "for hour in hours:\n",
    "    dfs = []\n",
    "    for mic_number in range(4):\n",
    "        if(not os.path.isdir('/home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes' + str(mic_number) + '/' + date + '/' + hour + '/')):\n",
    "            continue\n",
    "\n",
    "        for file in glob.glob('/home/ardelalegre/google-drive/ODAS/localization_dataframes/dataframes' + str(mic_number) + '/' + date +'/' + hour + '/*.csv'):\n",
    "            print(\"Reading file \" + file) \n",
    "            df = pd.read_csv(file)\n",
    "            dfs.append(df)\n",
    "    if(len(dfs) > 0):\n",
    "        merged = pd.concat(dfs)\n",
    "        #sort by time\n",
    "        merged = merged.sort_values(['Time In Seconds'])\n",
    "\n",
    "        if(not os.path.isdir(date_path)):\n",
    "            os.makedirs(date_path)\n",
    "        merged.to_csv(path_or_buf=date_path + '/' + hour + '.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
